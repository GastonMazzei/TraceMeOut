{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TraceMeOut-4GoogleColab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NJdGVNSkPlx",
        "outputId": "05c43afd-06d8-4379-ecca-9a7f85c04fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import pickle,sys,os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/GastonMazzei/TraceMeOut/blob/main/processed_trace/Dataset0.pkl?raw=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRjDxDxSlffM",
        "outputId": "42e96301-592c-4a1e-da80-c35001014871"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-29 23:46:17--  https://github.com/GastonMazzei/TraceMeOut/blob/main/processed_trace/Dataset0.pkl?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/GastonMazzei/TraceMeOut/raw/main/processed_trace/Dataset0.pkl [following]\n",
            "--2021-12-29 23:46:17--  https://github.com/GastonMazzei/TraceMeOut/raw/main/processed_trace/Dataset0.pkl\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/GastonMazzei/TraceMeOut/main/processed_trace/Dataset0.pkl [following]\n",
            "--2021-12-29 23:46:17--  https://raw.githubusercontent.com/GastonMazzei/TraceMeOut/main/processed_trace/Dataset0.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3095332 (3.0M) [application/octet-stream]\n",
            "Saving to: ‘Dataset0.pkl?raw=true’\n",
            "\n",
            "Dataset0.pkl?raw=tr 100%[===================>]   2.95M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-12-29 23:46:18 (74.0 MB/s) - ‘Dataset0.pkl?raw=true’ saved [3095332/3095332]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeBPa_RrlnaD",
        "outputId": "1f51841d-b5ad-4ff8-bd9e-efa7ec2f648c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Dataset0.pkl?raw=true'   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('Dataset0.pkl?raw=true','rb') as f:\n",
        "  data = pickle.load(f)"
      ],
      "metadata": {
        "id": "_AFenX9QlrWx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Model-specific parameters\n",
        "T=8 # duration of the window in dt units\n",
        "dt = 100000 # time in microseconds\n",
        "UNIQUES=3807  #number of unique ids\n",
        "MI=5709  #max number of interactions\n",
        "ML=5712  #max number of leaves\n",
        "NCATEGORIES=2\n",
        "\n",
        "# Architectural parameters\n",
        "ACT1 = 'relu'\n",
        "FILTERS1 = 8\n",
        "KSIZE1 = (2,1)\n",
        "PSIZE1 = (max([T//4,2]),)\n",
        "NDENSE1 = 16\n",
        "DROP1 = 0.4\n",
        "\n",
        "ACT2 = 'relu'\n",
        "FILTERS2 = 8\n",
        "KSIZE2 = (2,2)\n",
        "PSIZE2 = (max([T//2,2]),1)\n",
        "stride = (1,1)\n",
        "NDENSE2 = 16\n",
        "DROP2 = 0.75\n",
        "\n",
        "ACT3='relu'\n",
        "NDENSE3=8\n",
        "DROP3 = 0.4\n",
        "\n",
        "# Training parameters\n",
        "VAL=0.25\n",
        "BATCH=10\n",
        "EPOCHS=3\n",
        "L=5 # a length used to generate random data just for testing\n",
        "\n",
        "# Extras\n",
        "POOLING = False\n",
        "PROCS=[3, 2, 0, 1]"
      ],
      "metadata": {
        "id": "nsC-H7jvkmMn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define two sets of inputs: \n",
        "input_shape_flavours = (BATCH, T, ML, 1)\n",
        "input_shape_structure = (BATCH, T, MI, 2)\n",
        "inputFlavours = tf.keras.Input(shape=input_shape_flavours[1:])\n",
        "inputStructure = tf.keras.Input(shape=input_shape_structure[1:])\n",
        "\n",
        "# the first branch operates on the first input (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D)\n",
        "x = tf.keras.layers.Conv2D(\n",
        "\t\t\t# Filters, Kersize, Strides, Padding,  Activation\n",
        "\t\t\tFILTERS1,         KSIZE1,       (1,1),      'valid',  activation = ACT1,\n",
        "\t\t\tinput_shape = input_shape_flavours[1:]\n",
        "\t\t\t)(inputFlavours)\n",
        "x = tf.keras.layers.Conv2D(\n",
        "\t\t\t# Filters, Kersize, Strides, Padding,  Activation\n",
        "\t\t\tFILTERS1 * 2,         KSIZE1,       (1,1),      'valid',  activation = ACT1,\n",
        "\t\t\t)(x)\n",
        "x = tf.keras.layers.Conv2D(\n",
        "\t\t\t# Filters, Kersize, Strides, Padding,  Activation\n",
        "\t\t\tFILTERS1 * 2,         KSIZE1,       (1,1),      'valid',  activation = ACT1,\n",
        "\t\t\t)(x)\n",
        "#x = tf.keras.layers.MaxPool1D(pool_size=PSIZE1)(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dropout(DROP1)(x)\n",
        "x = tf.keras.layers.Dense(NDENSE1, activation = ACT1)(x)\n",
        "x = tf.keras.layers.Dropout(DROP1)(x)\n",
        "x = tf.keras.layers.Dense(NDENSE1 // 2, activation = ACT1)(x)\n",
        "x = tf.keras.layers.Dropout(DROP1)(x)\n",
        "x = tf.keras.layers.Dense(NDENSE1 // 2 // 2, activation = ACT1)(x)\n",
        "x = tf.keras.Model(inputs = inputFlavours, outputs=x)\n",
        "\n",
        "# the second branch opreates on the second input (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
        "y = tf.keras.layers.Conv2D(\n",
        "\t\t\t# Filters, Kersize, Strides, Padding,  Activation\n",
        "\t\t\tFILTERS2,         KSIZE2,    stride,      'valid',  activation = ACT2,\n",
        "\t\t\tinput_shape = input_shape_structure[1:]\n",
        "\t\t\t)(inputStructure)\n",
        "y = tf.keras.layers.Conv2D(\n",
        "\t\t\t# Filters, Kersize, Strides, Padding,  Activation\n",
        "\t\t\tFILTERS2 * 2,         KSIZE2,       stride,      'valid',  activation = ACT2,\n",
        "\t\t\t)(y)\n",
        "#y = tf.keras.layers.MaxPool2D(pool_size=PSIZE2)(y)\n",
        "y = tf.keras.layers.Conv2D(\n",
        "\t\t\t# Filters, Kersize, Strides, Padding,  Activation\n",
        "\t\t\tFILTERS2 * 2,         KSIZE2,       stride,      'valid',  activation = ACT2,\n",
        "\t\t\t)(y)\n",
        "y = tf.keras.layers.MaxPool2D(pool_size=PSIZE2)(y)\n",
        "y = tf.keras.layers.Flatten()(y)\n",
        "y = tf.keras.layers.Dropout(DROP2)(y)\n",
        "y = tf.keras.layers.Dense(NDENSE2, activation = ACT2)(y)\n",
        "y = tf.keras.layers.Dropout(DROP2)(y)\n",
        "y = tf.keras.layers.Dense(NDENSE2 // 2, activation = ACT2)(y)\n",
        "y = tf.keras.layers.Dropout(DROP2)(y)\n",
        "y = tf.keras.layers.Dense(NDENSE2 // 2 // 2, activation = ACT2)(y)\n",
        "y = tf.keras.Model(inputs = inputStructure, outputs=y)\n",
        "\n",
        "\n",
        "\n",
        "# combine the output of the two branches\n",
        "combined = tf.keras.layers.concatenate([x.output, y.output])\n",
        "z = tf.keras.layers.Dropout(DROP3)(combined)\n",
        "z = tf.keras.layers.Dense(NDENSE3, activation = ACT3)(z)\n",
        "z = tf.keras.layers.Dropout(DROP3)(z)\n",
        "z = tf.keras.layers.Dense(NDENSE3, activation = ACT3)(z)\n",
        "z = tf.keras.layers.Dense(NCATEGORIES, activation=\"softmax\")(z)\n",
        "\n",
        "# our model will accept the inputs of the two branches and\n",
        "# then output a single value\n",
        "model = tf.keras.Model(inputs=[x.input, y.input], outputs=z)\n",
        "\n",
        "# Compile the model :-)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.CategoricalCrossentropy(),\n",
        "                       tf.keras.metrics.AUC()])\n",
        "\n",
        "\n",
        "# Print input size and make fake dataset\n",
        "print(model.summary())\n",
        "IShape = model.input_shape\n",
        "OShape = model.output_shape\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g4gcQStkS5q",
        "outputId": "98ff0334-117f-4022-e53c-3453cc07fec0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 8, 5709, 2)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 8, 5712, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 7, 5708, 8)   72          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 7, 5712, 8)   24          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 6, 5707, 16)  528         ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 6, 5712, 16)  272         ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 5, 5706, 16)  1040        ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 5, 5712, 16)  528         ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 1, 5706, 16)  0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 456960)       0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 91296)        0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 456960)       0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 91296)        0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 16)           7311376     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 16)           1460752     ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 16)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 16)           0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 8)            136         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 8)            136         ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 8)            0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 8)            0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            36          ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 4)            36          ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8)            0           ['dense_2[0][0]',                \n",
            "                                                                  'dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 8)            0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 8)            72          ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 8)            0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 8)            72          ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 2)            18          ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,775,098\n",
            "Trainable params: 8,775,098\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X1, X20, Y = data['X1'],data['X2'],data['Y']\n",
        "ONE_HOT_Y = np.zeros((len(Y),2))\n",
        "for i in range(len(Y)):\n",
        "    ONE_HOT_Y[i,Y[i]] = 1\n",
        "ONE_HOT_Y = ONE_HOT_Y.astype('float32')\n",
        "L = len(X1)\n",
        "LTR = int(L*(1-VAL))\n",
        "B = 10\n",
        "LTR = LTR//B * B # LTR is approximated to the closest multiple of B :-)\n",
        "LVA = L - LTR\n",
        "LVA = LVA // B * B # THe same for LVA\n",
        "BATCH = BATCH // B * B # And the same for Batch Size\n",
        "\n",
        "assert(len(X1)==len(X20)==len(Y))\n",
        "\n",
        "X1_TRACKER = []\n",
        "for X_ in X1:\n",
        "    X1_TRACKER.append((ML-len(X_)))\n",
        "\n",
        "X2 = [[] for _ in range(len(X20))]\n",
        "X2_TRACKER = []\n",
        "for i,X_ in enumerate(X20):\n",
        "    c = 0\n",
        "    for i_,y_ in enumerate(X_):\n",
        "        for z in y_:\n",
        "            X2[i] += [[float(i_),float(z)]]\n",
        "            c += 1\n",
        "    X2_TRACKER.append(MI-c) \n",
        "\n",
        "\n",
        "def produce_data(A,B):\n",
        "    w = list(range(A,B))\n",
        "    np.random.shuffle(w)\n",
        "    for i in w:\n",
        "            yield (\n",
        "                    ( tf.convert_to_tensor(np.asarray([ (X1[j] + [0.] * X1_TRACKER[j]) for j in range(i-T+1,i+1)]).reshape(1,T,-1,1)), \n",
        "                      tf.convert_to_tensor(np.asarray([ (X2[j] + [[0., 0.]] * X2_TRACKER[j]) for j in range(i-T+1,i+1)]).reshape(1,T,-1,2)),\n",
        "                    ), \n",
        "                    tf.convert_to_tensor(ONE_HOT_Y[i:i+1,:].reshape(1,2)),\n",
        "                  )\n",
        "    yield None\n",
        "\n",
        "\n",
        "OS = (\n",
        "          (tf.TensorSpec(shape=(None,8,5712,1), dtype=tf.float32),\n",
        "          tf.TensorSpec(shape=(None,8,5709,2), dtype=tf.float32)),\n",
        "          tf.TensorSpec(shape=(None,2), dtype=tf.float32),\n",
        "    )\n",
        "\n",
        "print(f'Finished building the output structure')\n",
        "trainD = tf.data.Dataset.from_generator(lambda: produce_data(T,LTR), output_signature=OS)#output_types=(tf.float32), output_shapes=OS)\n",
        "print(f'Finished building the training dataset')\n",
        "valD = tf.data.Dataset.from_generator(lambda: produce_data(LTR+T,L), output_signature=OS)# output_types=(tf.float32), output_shapes=OS)\n",
        "print(f'Finished building the validation dataset')\n",
        "\n",
        "print(f'About to train! :-)')\n",
        "history = model.fit(trainD, epochs=1, batch_size=200, validation_data=valD, verbose=2)\n",
        "\n",
        "# Train\n",
        "\n",
        "# Display results\n",
        "print(history.history.keys())\n",
        "f,ax = plt.subplots(1,2,figsize=(15,10))\n",
        "ax[0].plot(history.history['loss'],label='loss')\n",
        "ax[0].plot(history.history['val_loss'], label='val loss')\n",
        "ax[0].legend()\n",
        "ax[1].plot(history.history['auc'],label='auc')\n",
        "ax[1].plot(history.history['val_auc'], label='val auc')\n",
        "ax[1].set_ylim(0,1)\n",
        "ax[1].legend()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9ykTxt9Ll-8Y",
        "outputId": "7b7c041d-dc8f-4769-88ae-f48fc93d7bc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished building the output structure\n",
            "Finished building the training dataset\n",
            "Finished building the validation dataset\n",
            "About to train! :-)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-19e0ca300984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'About to train! :-)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (model_2/dense_8/Softmax:0) = ] [[-nan -nan]] [y (Cast_3/x:0) = ] [0]\n\t [[node assert_greater_equal/Assert/AssertGuard/Assert\n (defined at /usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py:611)\n]] [Op:__inference_train_function_2046]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node assert_greater_equal/Assert/AssertGuard/Assert:\nIn[0] assert_greater_equal/Assert/AssertGuard/Assert/assert_greater_equal/All:\t\nIn[1] assert_greater_equal/Assert/AssertGuard/Assert/data_0:\t\nIn[2] assert_greater_equal/Assert/AssertGuard/Assert/data_1:\t\nIn[3] assert_greater_equal/Assert/AssertGuard/Assert/data_2:\t\nIn[4] assert_greater_equal/Assert/AssertGuard/Assert/model_2/dense_8/Softmax:\t\nIn[5] assert_greater_equal/Assert/AssertGuard/Assert/data_4:\t\nIn[6] assert_greater_equal/Assert/AssertGuard/Assert/Cast_3/x:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n>>>     handler_func(fileobj, events)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-8-19e0ca300984>\", line 59, in <module>\n>>>     history = model.fit(trainD, epochs=1, batch_size=200, validation_data=valD, verbose=2)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 817, in train_step\n>>>     self.compiled_metrics.update_state(y, y_pred, sample_weight)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 460, in update_state\n>>>     metric_obj.update_state(y_t, y_p, sample_weight=mask)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 73, in decorated\n>>>     update_op = update_state_fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 177, in update_state_fn\n>>>     return ag_update_state(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 2360, in update_state\n>>>     label_weights=label_weights)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 611, in update_confusion_matrix_variables\n>>>     message='predictions must be >= 0'),\n>>> \n\nFunction call stack:\ntrain_function -> assert_greater_equal_Assert_AssertGuard_false_1907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rktl-jpbmLRR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j0VBVFx0nMh2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}